{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1dddeae",
   "metadata": {},
   "source": [
    "# Jatin Deshpande (21b080014) - True Beacon Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5b1f0b",
   "metadata": {},
   "source": [
    "## Pairs Trading Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6f1dbd",
   "metadata": {},
   "source": [
    "### Before creating our strategy let us first analyse our data and the check for the pair given for pairs trading strategy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b11916a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import zscore\n",
    "from statsmodels.tsa.stattools import coint\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6549052b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>banknifty</th>\n",
       "      <th>nifty</th>\n",
       "      <th>tte</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-01-01 09:15:00</th>\n",
       "      <td>0.286058</td>\n",
       "      <td>0.199729</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-01 09:16:00</th>\n",
       "      <td>0.285381</td>\n",
       "      <td>0.200433</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-01 09:17:00</th>\n",
       "      <td>0.284233</td>\n",
       "      <td>0.200004</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-01 09:18:00</th>\n",
       "      <td>0.286104</td>\n",
       "      <td>0.199860</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-01 09:19:00</th>\n",
       "      <td>0.285539</td>\n",
       "      <td>0.198951</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-30 15:26:00</th>\n",
       "      <td>0.240701</td>\n",
       "      <td>0.214758</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-30 15:27:00</th>\n",
       "      <td>0.240875</td>\n",
       "      <td>0.216558</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-30 15:28:00</th>\n",
       "      <td>0.242115</td>\n",
       "      <td>0.216794</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-30 15:29:00</th>\n",
       "      <td>0.243426</td>\n",
       "      <td>0.216455</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-30 15:30:00</th>\n",
       "      <td>0.241907</td>\n",
       "      <td>0.216081</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180856 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     banknifty     nifty  tte\n",
       "time                                         \n",
       "2021-01-01 09:15:00   0.286058  0.199729   27\n",
       "2021-01-01 09:16:00   0.285381  0.200433   27\n",
       "2021-01-01 09:17:00   0.284233  0.200004   27\n",
       "2021-01-01 09:18:00   0.286104  0.199860   27\n",
       "2021-01-01 09:19:00   0.285539  0.198951   27\n",
       "...                        ...       ...  ...\n",
       "2022-06-30 15:26:00   0.240701  0.214758   28\n",
       "2022-06-30 15:27:00   0.240875  0.216558   28\n",
       "2022-06-30 15:28:00   0.242115  0.216794   28\n",
       "2022-06-30 15:29:00   0.243426  0.216455   28\n",
       "2022-06-30 15:30:00   0.241907  0.216081   28\n",
       "\n",
       "[180856 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taking data relevant to indian trading time which is given.\n",
    "data=pd.read_parquet(\"data.parquet\")\n",
    "data = data.between_time('09:15', '15:30').copy()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12794ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling the missing values \n",
    "missing_values = data.isnull().sum()\n",
    "if missing_values.sum() > 0:\n",
    "    data_filled = data.fillna(method='ffill')\n",
    "else:\n",
    "    data_filled = data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cb45e7",
   "metadata": {},
   "source": [
    "### Here we are using ffill because we don't want to miss important data_points from other row if we omit and also we dont want to exit/entry our trade due to such values, which can also happen if we bfill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff84d140",
   "metadata": {},
   "source": [
    "## Now if we can use them for paris trading we need to perform the following test, where we will check if they are cointegrated or not.\n",
    "\n",
    "### Here we use the \"Engle Granger tests\" - The idea of Engle-Granger test is simple. We perform a linear regression between the two asset prices and check if the residual is stationary using the Augmented Dick-Fuller (ADF) test. \n",
    "\n",
    "#### Reference for the test and related concepts: 1) https://hudsonthames.org/an-introduction-to-cointegration/    \n",
    "#### 2) https://arxiv.org/pdf/2211.07080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e199f515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The time series are cointegrated.\n"
     ]
    }
   ],
   "source": [
    "_, pvalue, _ = coint(data_filled['banknifty'],data_filled['nifty'])\n",
    "\n",
    "if pvalue <0.05:\n",
    "    print(\"The time series are cointegrated.\")\n",
    "else:\n",
    "    print(\"The time series are not cointegrated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af465802",
   "metadata": {},
   "source": [
    "## Base model - A very simple z-score based model to give trading signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0b86566",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filled['spread'] = data_filled['banknifty'] - data_filled['nifty']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4387f479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>banknifty</th>\n",
       "      <th>nifty</th>\n",
       "      <th>tte</th>\n",
       "      <th>spread</th>\n",
       "      <th>z_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-01-01 09:15:00</th>\n",
       "      <td>0.286058</td>\n",
       "      <td>0.199729</td>\n",
       "      <td>27</td>\n",
       "      <td>0.086329</td>\n",
       "      <td>0.543747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-01 09:16:00</th>\n",
       "      <td>0.285381</td>\n",
       "      <td>0.200433</td>\n",
       "      <td>27</td>\n",
       "      <td>0.084948</td>\n",
       "      <td>0.491736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-01 09:17:00</th>\n",
       "      <td>0.284233</td>\n",
       "      <td>0.200004</td>\n",
       "      <td>27</td>\n",
       "      <td>0.084229</td>\n",
       "      <td>0.464628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-01 09:18:00</th>\n",
       "      <td>0.286104</td>\n",
       "      <td>0.199860</td>\n",
       "      <td>27</td>\n",
       "      <td>0.086244</td>\n",
       "      <td>0.540526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-01 09:19:00</th>\n",
       "      <td>0.285539</td>\n",
       "      <td>0.198951</td>\n",
       "      <td>27</td>\n",
       "      <td>0.086588</td>\n",
       "      <td>0.553505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     banknifty     nifty  tte    spread   z_score\n",
       "time                                                             \n",
       "2021-01-01 09:15:00   0.286058  0.199729   27  0.086329  0.543747\n",
       "2021-01-01 09:16:00   0.285381  0.200433   27  0.084948  0.491736\n",
       "2021-01-01 09:17:00   0.284233  0.200004   27  0.084229  0.464628\n",
       "2021-01-01 09:18:00   0.286104  0.199860   27  0.086244  0.540526\n",
       "2021-01-01 09:19:00   0.285539  0.198951   27  0.086588  0.553505"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_filled['z_score'] = zscore(data_filled['spread'])\n",
    "\n",
    "data_filled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9087572c",
   "metadata": {},
   "source": [
    "### Some important assumptions: 1) We will make two column one for long trade i.e we are going long on the spread if the value of the spread goes below a arbiratry threshold from mean and one for short trade i.e short on spread if value of spread goes above a arbiratry threshold from mean. 2) We will not make multiple long or short trades at a time. 3) We will exit the trade if it goes beyond 5 days i.e 1875 minutes 3) We also assume that P/L for a trade will be difference between the P/L when we bought an\n",
    "\n",
    "### At each point of trade we are assuming that we know the entire data i.e all the datapoints from where we calculate the mean, this is not at all possible in actual market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aae200f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filled.insert(loc=5,column='signal_1',value=0)\n",
    "data_filled.insert(loc=6,column='signal_2',value=0)\n",
    "\n",
    "\n",
    "i=0\n",
    "while i<len(data_filled)-30:\n",
    "    #print(i)\n",
    "    count=1\n",
    "    if data_filled.iloc[i,4]>=1.5:\n",
    "        data_filled.iloc[i,5]=2\n",
    "        while ((i+count)<(len(data_filled)-1) and data_filled.iloc[i+count,4]>=0.5 and count<=1875):\n",
    "            #print(count)\n",
    "            data_filled.iloc[i+count,5]=1\n",
    "            count=count+1\n",
    "        data_filled.iloc[(i+count),5]=3\n",
    "    if count>1875:\n",
    "        i = i+count+1\n",
    "    else:\n",
    "        i=i+count\n",
    "\n",
    "i=0\n",
    "while i<len(data_filled)-30:\n",
    "    #print(i)\n",
    "    count=1\n",
    "    if data_filled.iloc[i,4]<=-1.5:\n",
    "        data_filled.iloc[i,6]=2\n",
    "        while ((i+count)<(len(data_filled)-1) and data_filled.iloc[i+count,4]<=-0.5 and count<=1875):\n",
    "            #print(count)\n",
    "            data_filled.iloc[i+count,6]=1\n",
    "            count=count+1\n",
    "        data_filled.iloc[(i+count),6]=3\n",
    "        \n",
    "    if count>1875:\n",
    "        i = i+count+1\n",
    "    else:\n",
    "        i=i+count\n",
    "\n",
    "\n",
    "data_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947b2e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,15))\n",
    "plt.plot(data_filled['signal_1'],'g')\n",
    "plt.plot(data_filled['signal_2'],'r')\n",
    "plt.plot(data_filled['z_score'],'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1857a386",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating P/L, when the signal is 2 it gives us the value when we entered the trade. \n",
    "#Similarly calculating P/L when the signal is 3 gives us the value when we exit the trade.\n",
    "data_filled.insert(loc=7,column='P/L',value=0)\n",
    "data_filled.loc[data_filled['signal_1']==2,'P/L']=data_filled['spread']*(data_filled['tte'])**0.7\n",
    "data_filled.loc[data_filled['signal_1']==3,'P/L']=data_filled['spread']*(data_filled['tte'])**0.7\n",
    "data_filled.loc[data_filled['signal_2']==2,'P/L']=data_filled['spread']*(data_filled['tte'])**0.7\n",
    "data_filled.loc[data_filled['signal_2']==3,'P/L']=data_filled['spread']*(data_filled['tte'])**0.7\n",
    "data_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc5ab93",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_Entry_1 = data_filled['signal_1'].value_counts()[2]\n",
    "count_Exit_1 = data_filled['signal_1'].value_counts()[3]\n",
    "\n",
    "count_Entry_2 = data_filled['signal_2'].value_counts()[2]\n",
    "count_Exit_2 = data_filled['signal_2'].value_counts()[3]\n",
    "\n",
    "print(count_Entry_1,count_Exit_1,count_Entry_2,count_Exit_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a96af6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_1=data_filled.loc[data_filled['signal_1']==2,'P/L'].sum()\n",
    "exit_1=data_filled.loc[data_filled['signal_1']==3,'P/L'].sum()\n",
    "#this is shorting the spread hence entry - exit\n",
    "return_1=(entry_1-exit_1)\n",
    "print(return_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350281f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_2=data_filled.loc[data_filled['signal_2']==2,'P/L'].sum()\n",
    "exit_2=data_filled.loc[data_filled['signal_2']==3,'P/L'].sum()\n",
    "#this is long on the spread hence exit - entry\n",
    "return_2=(exit_2-entry_2)\n",
    "print(return_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434a3b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_trades = count_Entry_1 + count_Entry_2\n",
    "avg_pnl = (return_1 + return_2)/total_trades # Average PNL\n",
    "avg_pnl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23f8d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = []\n",
    "for i in range(len(data_filled)):\n",
    "    if data_filled.iloc[i,5]==2:\n",
    "        ent = data_filled.iloc[i,7]\n",
    "        count = 1\n",
    "        while data_filled.iloc[i+count,5]!=3 and count<1805:\n",
    "            count+=1\n",
    "        ext = data_filled.iloc[i+count,7]\n",
    "        returns.append(ent-ext)\n",
    "    if data_filled.iloc[i,6]==2:\n",
    "        ent = data_filled.iloc[i,7]\n",
    "        count = 1\n",
    "        while data_filled.iloc[i+count,6]!=3:\n",
    "            count+=1\n",
    "        ext = data_filled.iloc[i+count,7]\n",
    "        returns.append(ext-ent)\n",
    "returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88a4ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns_a = np.array(returns)\n",
    "sharpe_ratio = (returns_a.mean()-.106)/returns_a.std()\n",
    "sharpe_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4f1359",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_drawdown(returns):\n",
    "    cumulative_returns = np.cumprod(1 + returns)\n",
    "    peak = np.maximum.accumulate(cumulative_returns)\n",
    "    drawdown = (cumulative_returns - peak) / peak\n",
    "    max_drawdown = np.abs(np.min(drawdown))\n",
    "    return max_drawdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed700442",
   "metadata": {},
   "outputs": [],
   "source": [
    "maximum_drawdown = max_drawdown(returns_a)\n",
    "print(\"Maximum Drawdown:\", maximum_drawdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebccbd4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad61851",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "628dc02f",
   "metadata": {},
   "source": [
    "## Goal --> Stabilise Spread\n",
    "\n",
    "### Z-Score Strategy,\n",
    "$$(\\text{BankNifty - Nifty}) \\sim \\text{f(Nifty)} = \\alpha + (\\beta - 1) \\text{nifty} + \\mu $$\n",
    "#### Mean(Spread) is not constant for all observations but depends on the variable Nifty\n",
    "### New Strategy,\n",
    "$$\\text{Spread} = (\\text{BankNifty} - \\beta.\\text{Nifty}) - \\alpha = \\mu$$\n",
    "$$\\text{Mean(Spread)} = 0 ; \\text{Var(Spread)} = \\sigma^2$$\n",
    "### Assumption -> $E[\\mu]=0$ (from normal equations of OLS)\n",
    "#### A good estimator for $\\mu \\sim \\hat{\\mu}$(residual)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc3bc2f",
   "metadata": {},
   "source": [
    "## Approach 1 - Regression model without train/test spilt with some issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282571fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_model=pd.read_parquet(\"data.parquet\")\n",
    "data_model = data_model.between_time('09:15', '15:30').copy()\n",
    "missing_values = data.isnull().sum()\n",
    "if missing_values.sum() > 0:\n",
    "    data_m1 = data_model.fillna(method='ffill')\n",
    "else:\n",
    "    data_m1 = data_model\n",
    "data_m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75c1ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a constant term to the independent variable (x)\n",
    "x_with_const = sm.add_constant(data_m1['nifty'])\n",
    "\n",
    "# Fit the linear regression model\n",
    "model = sm.OLS(data_m1['banknifty'], x_with_const).fit()\n",
    "\n",
    "# Get the predicted values (fitted values)\n",
    "predicted_values = model.predict(x_with_const)\n",
    "\n",
    "# Calculate residuals\n",
    "data_m1['residuals'] = data_m1['banknifty'] - predicted_values\n",
    "\n",
    "data_m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ac3122",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data_m1['residuals'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfee090",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_m1['z_score'] = zscore(data_m1['residuals'])\n",
    "plt.plot(data_m1['z_score'])\n",
    "data_m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4914ecf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_m1.insert(loc=5,column='signal_1',value=0)\n",
    "data_m1.insert(loc=6,column='signal_2',value=0)\n",
    "\n",
    "\n",
    "i=0\n",
    "while i<len(data_m1)-30:\n",
    "    #print(i)\n",
    "    count=1\n",
    "    if data_m1.iloc[i,4]>=1.5:\n",
    "        data_m1.iloc[i,5]=2\n",
    "        while ((i+count)<(len(data_m1)-1) and data_m1.iloc[i+count,4]>=0.5 and count<=1875):\n",
    "            #print(count)\n",
    "            data_m1.iloc[i+count,5]=1\n",
    "            count=count+1\n",
    "        data_m1.iloc[(i+count),5]=3\n",
    "    if count>1875:\n",
    "        i = i+count+1\n",
    "    else:\n",
    "        i=i+count\n",
    "\n",
    "i=0\n",
    "while i<len(data_m1)-30:\n",
    "    #print(i)\n",
    "    count=1\n",
    "    if data_m1.iloc[i,4]<=-1.5:\n",
    "        data_m1.iloc[i,6]=2\n",
    "        while ((i+count)<(len(data_m1)-1) and data_m1.iloc[i+count,4]<=-0.5 and count<=1875):\n",
    "            #print(count)\n",
    "            data_m1.iloc[i+count,6]=1\n",
    "            count=count+1\n",
    "        data_m1.iloc[(i+count),6]=3\n",
    "        \n",
    "    if count>1875:\n",
    "        i = i+count+1\n",
    "    else:\n",
    "        i=i+count\n",
    "\n",
    "\n",
    "data_m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bad275",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,15))\n",
    "plt.plot(data_m1['signal_1'],'g')\n",
    "plt.plot(data_m1['signal_2'],'r')\n",
    "plt.plot(data_m1['z_score'],'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f1eeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_m1.insert(loc=7,column='P/L',value=0)\n",
    "data_m1.loc[data_m1['signal_1']==2,'P/L']=data_m1['residuals']*(data_filled['tte'])**0.7\n",
    "data_m1.loc[data_m1['signal_1']==3,'P/L']=data_m1['residuals']*(data_filled['tte'])**0.7\n",
    "data_m1.loc[data_m1['signal_2']==2,'P/L']=data_m1['residuals']*(data_filled['tte'])**0.7\n",
    "data_m1.loc[data_m1['signal_2']==3,'P/L']=data_m1['residuals']*(data_filled['tte'])**0.7\n",
    "data_m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029094ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_Entry_1 = data_m1['signal_1'].value_counts()[2]\n",
    "count_Exit_1 = data_m1['signal_1'].value_counts()[3]\n",
    "\n",
    "count_Entry_2 = data_m1['signal_2'].value_counts()[2]\n",
    "count_Exit_2 = data_m1['signal_2'].value_counts()[3]\n",
    "\n",
    "print(count_Entry_1,count_Exit_1,count_Entry_2,count_Exit_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a49113",
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_1=data_m1.loc[data_m1['signal_1']==2,'P/L'].sum()\n",
    "exit_1=data_m1.loc[data_m1['signal_1']==3,'P/L'].sum()\n",
    "#this is shorting the spread hence entry - exit\n",
    "return_1=(entry_1-exit_1)\n",
    "print(return_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636a8ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_2=data_m1.loc[data_m1['signal_2']==2,'P/L'].sum()\n",
    "exit_2=data_m1.loc[data_m1['signal_2']==3,'P/L'].sum()\n",
    "#this is long on the spread hence exit - entry\n",
    "return_2=(exit_2-entry_2)\n",
    "print(return_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788411a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_trades = count_Entry_1 + count_Entry_2\n",
    "avg_pnl = (return_1 + return_2)/total_trades # Average PNL\n",
    "avg_pnl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8978f8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = []\n",
    "for i in range(len(data_m1)):\n",
    "    if data_m1.iloc[i,5]==2:\n",
    "        ent = data_m1.iloc[i,7]\n",
    "        count = 1\n",
    "        while data_m1.iloc[i+count,5]!=3 and count<1805:\n",
    "            count+=1\n",
    "        ext = data_m1.iloc[i+count,7]\n",
    "        returns.append(ent-ext)\n",
    "    if data_m1.iloc[i,6]==2:\n",
    "        ent = data_m1.iloc[i,7]\n",
    "        count = 1\n",
    "        while data_m1.iloc[i+count,6]!=3:\n",
    "            count+=1\n",
    "        ext = data_m1.iloc[i+count,7]\n",
    "        returns.append(ext-ent)\n",
    "returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b5940f",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns_a = np.array(returns)\n",
    "sharpe_ratio = (returns_a.mean()-.106)/returns_a.std()\n",
    "sharpe_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7b5ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_drawdown(returns):\n",
    "    cumulative_returns = np.cumprod(1 + returns)\n",
    "    peak = np.maximum.accumulate(cumulative_returns)\n",
    "    drawdown = (cumulative_returns - peak) / peak\n",
    "    max_drawdown = np.abs(np.min(drawdown))\n",
    "    return max_drawdown\n",
    "\n",
    "maximum_drawdown = max_drawdown(returns_a)\n",
    "print(\"Maximum Drawdown:\", maximum_drawdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0591d986",
   "metadata": {},
   "source": [
    "## Drawbacks and issues with the above model:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d418528",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9bb4cf91",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545c889a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc513a03",
   "metadata": {},
   "source": [
    "# We will try to address some issues now in above model and move little towards a real case scenario\n",
    "## Approach 2 - Regression model with train/test spilt \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7f2fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating data and handling the missing values\n",
    "data_3=pd.read_parquet(\"data.parquet\")\n",
    "data_3 = data_model.between_time('09:15', '15:30').copy()\n",
    "missing_values = data.isnull().sum()\n",
    "if missing_values.sum() > 0:\n",
    "    data_reg = data_model.fillna(method='ffill')\n",
    "else:\n",
    "    data_reg = data_model\n",
    "data_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00210e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spilting the data into traaining data and testing data. \n",
    "# Reason: As at particular time of trade we don't know the future values, hence we first find parameters from //\n",
    "# training data and then use them to produce signals on the test data.\n",
    "\n",
    "train= data_reg.loc[:'2021-10-29 15:15:00'].copy()\n",
    "test= data_reg.loc['2022-01-03 09:15:00':].copy()\n",
    "\n",
    "#Rolling regression can also be used instead of spilting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc02b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we first run a regression on training data to get the coefficients, and use these in test data //\n",
    "# to generate signals based on the z_score of spread calculated from this data on test data where spread is the resiudals.\n",
    "\n",
    "# Note: Here there are lot of assumptions in linear regression we are taking and can create \"biased\" //\n",
    "# or \"inefficient\" estimates of parameters\n",
    "\n",
    "\n",
    "# Add a constant term to the independent variable (x)\n",
    "x_with_const = sm.add_constant(train['nifty'])\n",
    "\n",
    "# Fit the linear regression model\n",
    "model = sm.OLS(train['banknifty'], x_with_const).fit()\n",
    "\n",
    "params = model.params\n",
    "\n",
    "# Also we will need mean and std of residuals here to use them in Z-score of test data\n",
    "\n",
    "# Get the predicted values (fitted values)\n",
    "predicted_values = model.predict(x_with_const)\n",
    "\n",
    "# Calculate residuals\n",
    "train['residuals'] = train['banknifty'] - predicted_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83394815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the parameters we need:\n",
    "residual_mean = train['residuals'].mean() \n",
    "residual_std = train['residuals'].std() \n",
    "\n",
    "#Regression parameters\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0443359a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(residual_mean, residual_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0f2b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = params.const\n",
    "beta = params.nifty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31eb286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have got our parameter from train data, let us calculate spread on test data with help of this parameters\n",
    "# residual_spread = y - y_hat = banknifty - (aplha + beta*nifty)\n",
    "\n",
    "test['residual_spread'] = test['banknifty'] - alpha - beta*test['nifty']\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddc82a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test['residual_spread'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c82d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CALCULATING Z-Score with help of mean and std from training dataset and residuals of test dataset //\n",
    "# obtained with the help of \"estimated\" parameters from training dataset\n",
    "\n",
    "test['Z_Score'] = (test['residual_spread'] - residual_mean)/residual_std\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a20cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test['Z_Score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e655d2",
   "metadata": {},
   "source": [
    "### In the above graph we can see and say that our spread or the zscore that we got is not stationary as we want because it is not as much oscilating around 0 and hence the mean or the parameters of it may be changing wrt time, and hence this method might not give accurate prediction about when to long or short the spread and hence we might need to imporve on this model maybe by calculating rolling z_score which updates it means periodically and also perform rolling regression that will update its parameter to give more stable residuals!\n",
    "\n",
    "There are various other methods as well which can be used, for now let us proceed with this Z_score and will comeback later to other methods so that we can refine and generate more good trading signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b7ff35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we got our Z-scores for our resiudal spread we can decided the thhreshold to enter a trade and exit a trade.\n",
    "# Here we assume that we can seprately place our long ansd short trade and if we are in a long or short trade //\n",
    "# new trade of same type can only be initiated if we exit our first position.\n",
    "\n",
    "# Before we decide on how are we trading let us create two columns in our test dataset, //\n",
    "# One of us which will store the long positions and other short positions.\n",
    "\n",
    "# Here it is important to understand the notion behind going long on spread and going short on spread, which //\n",
    "# lies at heart of pair trading strategies\n",
    "\n",
    "\n",
    "test.insert(loc=5,column='signal_1',value=0)\n",
    "test.insert(loc=6,column='signal_2',value=0)\n",
    "\n",
    "\n",
    "# Now let us understand some things on trades that we are entering and what assumptions we have made\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe16f2f1",
   "metadata": {},
   "source": [
    "### Here we decide our threshold for the diversion from mean based (Zscores) based on various factors.\n",
    "\n",
    "### But For now let us ignore the factors and arbitarily take some values to enter a trade and exit a trade.\n",
    "\n",
    "So when the Z-score is greater than 1.5 (assuming) we will enter a short the spread position that is we short the bank_nifty and go long on nifty and as soon as this falls again below 0.5 (assumption) we exit the trade. \n",
    "Theory lies at core of pairs trading startegy.\n",
    "\n",
    "## Very Important point to note : We will also exit the trade if we are in the trade for more than 5 days i.e due to medium frequency startegy but in real case we may benefit from staying if the spread still has large deviation from mean.\n",
    "\n",
    "Let us signal 2 if we are entering a trade as we get a signal and 3 when we exit, 1 is for when we are in the trade.\n",
    "### Also when we see P/L it can be seen that we won't be in a long and short position simulteanously \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ec965f",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "while i<len(test)-30:\n",
    "    #print(i)\n",
    "    count=1\n",
    "    if test.iloc[i,4]>=1.5:\n",
    "        test.iloc[i,5]=2\n",
    "        while ((i+count)<(len(test)-1) and test.iloc[i+count,4]>=0.5 and count<=1875):\n",
    "            #print(count)\n",
    "            test.iloc[i+count,5]=1\n",
    "            count=count+1\n",
    "        test.iloc[(i+count),5]=3\n",
    "    if count>1875:\n",
    "        i = i+count+1\n",
    "    else:\n",
    "        i=i+count\n",
    "\n",
    "i=0\n",
    "while i<len(test)-30:\n",
    "    #print(i)\n",
    "    count=1\n",
    "    if test.iloc[i,4]<=-1.5:\n",
    "        test.iloc[i,6]=2\n",
    "        while ((i+count)<(len(test)-1) and test.iloc[i+count,4]<=-0.5 and count<=1875):\n",
    "            #print(count)\n",
    "            test.iloc[i+count,6]=1\n",
    "            count=count+1\n",
    "        test.iloc[(i+count),6]=3\n",
    "        \n",
    "    if count>1875:\n",
    "        i = i+count+1\n",
    "    else:\n",
    "        i=i+count\n",
    "\n",
    "\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b139d2ce",
   "metadata": {},
   "source": [
    "### Also note we have decided the signals based on Zscore which are actually just taking into account the Z_Score at that time, there are various other startegies where we can build a momentum based startegy or some machine learning processes to create signals, for now let us proceed with this simple startegy and comeback later to other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41c1ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHOWS ARE WHAT TIME WE ARE ENTERING THE TRADE AND EXITING IN TRADE AND IF IT IS LONG/SHORT\n",
    "plt.plot(test['Z_Score'],'b')\n",
    "plt.plot(test['signal_1'],'r')\n",
    "plt.plot(test['signal_2'],'g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97462ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us also see number of trades we took for given time-period of test data\n",
    "count_Entry_short = test['signal_1'].value_counts()[2]\n",
    "count_Exit_short = test['signal_1'].value_counts()[3]\n",
    "\n",
    "count_Entry_long = test['signal_2'].value_counts()[2]\n",
    "count_Exit_long = test['signal_2'].value_counts()[3]\n",
    "\n",
    "print(count_Entry_short,count_Exit_short,count_Entry_long,count_Exit_long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb526ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We calculate P/L for each entry and exit, and then for net P/L we take difference of both later depending on long/short.\n",
    "\n",
    "test.insert(loc=7,column='P/L',value=0)\n",
    "test.loc[test['signal_1']==2,'P/L']=test['residual_spread']*((test['tte'])**0.7)\n",
    "test.loc[test['signal_2']==2,'P/L']=test['residual_spread']*((test['tte'])**0.7)\n",
    "test.loc[test['signal_1']==3,'P/L']=test['residual_spread']*((test['tte'])**0.7)\n",
    "test.loc[test['signal_2']==3,'P/L']=test['residual_spread']*((test['tte'])**0.7)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68425480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let us calculate net_p/l first for both long and short positions:\n",
    "\n",
    "entry_1=test.loc[test['signal_1']==2,'P/L'].sum()\n",
    "exit_1=test.loc[test['signal_1']==3,'P/L'].sum()\n",
    "#this is shorting the spread hence entry - exit\n",
    "return_1=(entry_1-exit_1)\n",
    "print(return_1)\n",
    "\n",
    "entry_2=test.loc[test['signal_2']==2,'P/L'].sum()\n",
    "exit_2=test.loc[test['signal_2']==3,'P/L'].sum()\n",
    "#this is long on the spread hence exit - entry\n",
    "return_2=(exit_2-entry_2)\n",
    "print(return_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9581a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now for comparing let us calculate average P/L per trade so that we can compare with other strtagies\n",
    "\n",
    "total_trades = count_Entry_long + count_Entry_short\n",
    "avg_pnl = (return_1 + return_2)/total_trades # Average PNL\n",
    "avg_pnl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7255eb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also for sharp ratio make a array and store returns for each trade executed separetely.\n",
    "\n",
    "returns = []\n",
    "for i in range(len(test)):\n",
    "    if test.iloc[i,5]==2:\n",
    "        ent = test.iloc[i,7]\n",
    "        count = 1\n",
    "        while test.iloc[i+count,5]!=3 and count<1805:\n",
    "            count+=1\n",
    "        ext = test.iloc[i+count,7]\n",
    "        returns.append(ent-ext)\n",
    "    if data_m1.iloc[i,6]==2:\n",
    "        ent = data_m1.iloc[i,7]\n",
    "        count = 1\n",
    "        while data_m1.iloc[i+count,6]!=3:\n",
    "            count+=1\n",
    "        ext = data_m1.iloc[i+count,7]\n",
    "        returns.append(ext-ent)\n",
    "returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373d849e",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns_a = np.array(returns)\n",
    "sharpe_ratio = (returns_a.mean()-.106)/returns_a.std()\n",
    "sharpe_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2b51d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the maximum drawdown from an array of returns.\n",
    "def max_drawdown(returns):\n",
    "    cumulative_returns = np.cumprod(1 + returns)\n",
    "    peak = np.maximum.accumulate(cumulative_returns)\n",
    "    drawdown = (cumulative_returns - peak) / peak\n",
    "    max_drawdown = np.abs(np.min(drawdown))\n",
    "    return max_drawdown\n",
    "\n",
    "maximum_drawdown = max_drawdown(returns_a)\n",
    "print(\"Maximum Drawdown:\", maximum_drawdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c3104e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6308ee5b",
   "metadata": {},
   "source": [
    "## Approach 3 - Using a rolling regression model as mentioned in above model.\n",
    "\n",
    "Lets hope we imporve our results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa6b8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the window size for the rolling regression \n",
    "window_size = 60 # Example window size, adjust based on analysis needs \n",
    "# Initialize the series to store the rolling regression residuals \n",
    "rolling_residuals = pd.Series(index=data_m1.index) \n",
    "# Perform rolling regression and calculate residuals \n",
    "for start in range(len(data_filled) - window_size): \n",
    "    end = start + window_size \n",
    "    X = sm.add_constant(data_m1['nifty'][start:end]) \n",
    "    # Predictor variable with constant \n",
    "    y = data_m1['banknifty'][start:end] \n",
    "    # Response variable \n",
    "    model = OLS(y, X).fit() \n",
    "    predictions = model.predict(X) \n",
    "    residuals = y - predictions \n",
    "    rolling_residuals[end:end+1] = residuals.iloc[-1] \n",
    "    # Fill the initial part of the series where rolling residuals are not available with the first available residual \n",
    "    rolling_residuals = rolling_residuals.fillna(method='bfill') \n",
    "    # Update the dataset with the rolling residuals \n",
    "    data_m1['rolling_residual_spread'] = rolling_residuals "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4601dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data_m1['rolling_residual_spread'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50b1336",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb06ce0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_m1['z_score_rolling'] = zscore(data_m1['rolling_residual_spread'])\n",
    "data_m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885d82a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data_m1['z_score_rolling'],'g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebef680b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_m1.insert(loc=10,column='signal_11',value=0)\n",
    "data_m1.insert(loc=11,column='signal_22',value=0)\n",
    "\n",
    "\n",
    "i=0\n",
    "while i<len(data_m1)-30:\n",
    "    #print(i)\n",
    "    count=1\n",
    "    if data_m1.iloc[i,9]>=1.5:\n",
    "        data_m1.iloc[i,10]=2\n",
    "        while ((i+count)<(len(data_m1)-1) and data_m1.iloc[i+count,9]>=0.5 and count<=1875):\n",
    "            #print(count)\n",
    "            data_m1.iloc[i+count,10]=1\n",
    "            count=count+1\n",
    "        data_m1.iloc[(i+count),10]=3\n",
    "    if count>1875:\n",
    "        i = i+count+1\n",
    "    else:\n",
    "        i=i+count\n",
    "\n",
    "i=0\n",
    "while i<len(data_m1)-30:\n",
    "    #print(i)\n",
    "    count=1\n",
    "    if data_m1.iloc[i,9]<=-1.5:\n",
    "        data_m1.iloc[i,11]=2\n",
    "        while ((i+count)<(len(data_m1)-1) and data_m1.iloc[i+count,9]<=-0.5 and count<=1875):\n",
    "            #print(count)\n",
    "            data_m1.iloc[i+count,11]=1\n",
    "            count=count+1\n",
    "        data_m1.iloc[(i+count),11]=3\n",
    "        \n",
    "    if count>1875:\n",
    "        i = i+count+1\n",
    "    else:\n",
    "        i=i+count\n",
    "\n",
    "\n",
    "data_m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c1f430",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_Entry_11 = data_m1['signal_11'].value_counts()[2]\n",
    "count_Exit_11 = data_m1['signal_11'].value_counts()[3]\n",
    "\n",
    "count_Entry_22 = data_m1['signal_22'].value_counts()[2]\n",
    "count_Exit_22 = data_m1['signal_22'].value_counts()[3]\n",
    "\n",
    "print(count_Entry_1,count_Exit_1,count_Entry_2,count_Exit_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d86c726",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_m1.insert(loc=12,column='P/L_2',value=0)\n",
    "data_m1.loc[data_m1['signal_11']==2,'P/L_2']=data_m1['rolling_residual_spread']*(data_filled['tte'])**0.7\n",
    "data_m1.loc[data_m1['signal_22']==2,'P/L_2']=data_m1['rolling_residual_spread']*(data_filled['tte'])**0.7\n",
    "data_m1.loc[data_m1['signal_11']==3,'P/L_2']=data_m1['rolling_residual_spread']*(data_filled['tte'])**0.7\n",
    "data_m1.loc[data_m1['signal_22']==3,'P/L_2']=data_m1['rolling_residual_spread']*(data_filled['tte'])**0.7\n",
    "data_m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba8dd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_1=data_m1.loc[data_m1['signal_11']==2,'P/L_2'].sum()\n",
    "exit_1=data_m1.loc[data_m1['signal_11']==3,'P/L_2'].sum()\n",
    "#this is shorting the spread hence entry - exit\n",
    "return_1=(entry_1-exit_1)\n",
    "print(return_1)\n",
    "\n",
    "entry_2=data_m1.loc[data_m1['signal_22']==2,'P/L_2'].sum()\n",
    "exit_2=data_m1.loc[data_m1['signal_22']==3,'P/L_2'].sum()\n",
    "#this is long on the spread hence exit - entry\n",
    "return_2=(exit_2-entry_2)\n",
    "print(return_2)\n",
    "\n",
    "total_trades = count_Entry_1 + count_Entry_2\n",
    "avg_pnl = (return_1 + return_2)/total_trades # Average PNL\n",
    "avg_pnl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1a3cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = []\n",
    "for i in range(len(data_m1)):\n",
    "    if data_m1.iloc[i,10]==2:\n",
    "        ent = data_m1.iloc[i,12]\n",
    "        count = 1\n",
    "        while data_m1.iloc[i+count,10]!=3 and count<1805:\n",
    "            count+=1\n",
    "        ext = data_m1.iloc[i+count,12]\n",
    "        returns.append(ent-ext)\n",
    "    if data_m1.iloc[i,11]==2:\n",
    "        ent = data_m1.iloc[i,12]\n",
    "        count = 1\n",
    "        while data_m1.iloc[i+count,11]!=3:\n",
    "            count+=1\n",
    "        ext = data_m1.iloc[i+count,12]\n",
    "        returns.append(ext-ent)\n",
    "returns\n",
    "\n",
    "returns_a = np.array(returns)\n",
    "sharpe_ratio = (returns_a.mean()-.106)/returns_a.std()\n",
    "print(sharpe_ratio)\n",
    "\n",
    "def max_drawdown(returns):\n",
    "    \"\"\"\n",
    "    Calculate the maximum drawdown from an array of returns.\n",
    "\n",
    "    Parameters:\n",
    "    returns (np.array): Array of returns.\n",
    "\n",
    "    Returns:\n",
    "    float: Maximum drawdown.\n",
    "    \"\"\"\n",
    "    cumulative_returns = np.cumprod(1 + returns)\n",
    "    peak = np.maximum.accumulate(cumulative_returns)\n",
    "    drawdown = (cumulative_returns - peak) / peak\n",
    "    max_drawdown = np.abs(np.min(drawdown))\n",
    "    return max_drawdown\n",
    "\n",
    "maximum_drawdown = max_drawdown(returns_a)\n",
    "print(\"Maximum Drawdown:\", maximum_drawdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbf4d5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15379f6a",
   "metadata": {},
   "source": [
    "# Other Approaches and Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28d13e9",
   "metadata": {},
   "source": [
    "### There are many other improvements in above 3 approaches that can be done and many different models that can be implemented.\n",
    "\n",
    "## If we try to break pairs trading as a whole into steps and then modify processes at each step that will optimize the results that we want, it can result into a robust strategy.\n",
    "### Though here we have not done optimization, it can be done by backtesting for several choice parameters.\n",
    "\n",
    "### Below I have specefied two approach or slight changes that can be brought in to produce some more efficient signals. Comparsion with above is not possible with the following models as they are based on various simplying assumptions, so they are just for information purpose. Important thing to note is the Mathematical approach behind one approach (Principal Component Analysis) and other one is based on chaning the way we create signals which is based on a momentum startegy (RSI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b931c90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cea85a7e",
   "metadata": {},
   "source": [
    "## PCA Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcd67e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_3=pd.read_parquet(\"data.parquet\")\n",
    "data_3 = data_model.between_time('09:15', '15:30').copy()\n",
    "missing_values = data.isnull().sum()\n",
    "if missing_values.sum() > 0:\n",
    "    data_pca = data_model.fillna(method='ffill')\n",
    "else:\n",
    "    data_pca = data_model\n",
    "data_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d3d88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To apply PCA first we bring down both to same scale i.e normalise the data\n",
    "\n",
    "# Calculate the IV spread between Bank Nifty and Nifty _ we are taking spread for test data by same logic //\n",
    "# we used earlier and using the resiudal spread instead of normal spread.\n",
    "\n",
    "train_pca= data_pca.loc[:'2021-10-29 15:15:00'].copy()\n",
    "test_pca= data_pca.loc['2022-01-03 09:15:00':].copy()\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Add a constant term to the independent variable (x)\n",
    "x_with_const = sm.add_constant(train_pca['nifty'])\n",
    "\n",
    "# Fit the linear regression model\n",
    "model = sm.OLS(train_pca['banknifty'], x_with_const).fit()\n",
    "\n",
    "params = model.params\n",
    "\n",
    "alpha = params.const\n",
    "beta = params.nifty\n",
    "\n",
    "test_pca['residual_spread'] = test_pca['banknifty'] - alpha - beta*test_pca['nifty']\n",
    "test_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a33741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the IV Spread for PCA\n",
    "scaler = StandardScaler()\n",
    "iv_spread_scaled = scaler.fit_transform(test_pca[['residual_spread']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af06ebe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA to the scaled IV Spread\n",
    "pca = PCA(n_components=1)  # Using 1 component since we're focusing on the IV spread\n",
    "pca.fit(iv_spread_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffaaba2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the IV spread data to the principal component space\n",
    "iv_spread_pca = pca.transform(iv_spread_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c269a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the principal component scores to the dataframe\n",
    "test_pca['iv_spread_pc1'] = iv_spread_pca[:, 0]\n",
    "test_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f0616b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Explained Variance Ratio\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "\n",
    "### Now, let's prepare to generate trading signals based on the first principal component\n",
    "### A simple strategy: Buy (1) when the score of PC1 increases, Sell (-1) when it decreases\n",
    "test_pca['signal'] = test_pca['iv_spread_pc1'].diff().apply(lambda x: 1 if x > 0 else (-1 if x < 0 else 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b72dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the P/L for trading signals, assuming 'tte' is the time to expiry\n",
    "# P/L = Spread * (TTE)^0.7 for trades\n",
    "# Note: This simplistic model does not account for bid-ask spread, transaction costs, or slippage\n",
    "test_pca['P/L'] = test_pca.apply(lambda row: row['residual_spread'] * (row['tte'] ** 0.7) if row['signal'] != 0 else 0, axis=1)\n",
    "test_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d83de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let us see how many times we have gone long and how many times short:\n",
    "print(test_pca['signal'].value_counts()[1])\n",
    "print(test_pca['signal'].value_counts()[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab063d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cumulative P/L as +1 in buying -1 is selling and we are ignoring the closing of trades here\n",
    "# So net P/L or the total P/L will be +1 x P/L + -1 x P/L\n",
    "long_net_P_L= test_pca.loc[test_pca['signal']==1,'P/L'].sum()\n",
    "\n",
    "short_net_P_L=test_pca.loc[test_pca['signal']==-1,'P/L'].sum()\n",
    "\n",
    "#this is long on the spread hence exit - entry\n",
    "Net_PL = long_net_P_L - short_net_P_L\n",
    "print(Net_PL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfc9b76",
   "metadata": {},
   "source": [
    "### In the above case main aim is to show how PCA can be used to generate signals rather than comparing it to our base model. We are ignoring the closing of trades here and assuming that we can long and short as much as we can and netPL is calulated which will differ in real case beacause positions need to be closed.\n",
    "\n",
    "## Also we have directly performed the PCA analysis with help of libaries but the underlying maths is as follows:\n",
    "\n",
    "### In short we are identfying major factors that are affecting our spread (Bank nifty - Nifty), and by analysing them we are creating signals. Reason to use is to reduce the complexity of data.\n",
    "\n",
    "The method to calculate this component is based on matrix algebra, for reference:\n",
    "Link:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4f348f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ef2f1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a0359a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd41b1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91616cb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8756a3dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03c537c9",
   "metadata": {},
   "source": [
    "# SSSSSSSSSSSSSSSSSSSSSSSSS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed08de1",
   "metadata": {},
   "source": [
    "# Now let us refine our approach to generate signals by the Z-Scores\n",
    "### We will use a momentum indicator generally used to asses price, but we also can asses Z-scores obtained with it, which is RSI (Relative Strength Index).\n",
    "\n",
    "RSI here - measures the speed and change of Z-score, it tells how significantly spread deviates from its mean.\n",
    "\n",
    "In short we are checking with RSI if Z-score is peaking or botoming out, which then will potentially signal a reversal!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80456d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate RSI \n",
    "def rsi(series, period=14): \n",
    "    delta = series.diff() \n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=period).mean() \n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean() \n",
    "    rs = gain / loss \n",
    "    return 100 - (100 / (1 + rs)) \n",
    "\n",
    "test['z_score_rsi'] = rsi(test['Z_Score'], period=14) \n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73b847b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling some null values generated due to rolling nature of rsi:\n",
    "\n",
    "test['z_score_rsi'] = test['z_score_rsi'].fillna(method='bfill')\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d266bf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['z_score_rsi'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ee1c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Long trades logic\n",
    "i = 0\n",
    "while i < len(test)-30:\n",
    "    count = 1\n",
    "    if test.iloc[i]['z_score_rsi'] <= lower_threshold:\n",
    "        test.iloc[i]['long_signal_rsi'] = 2  # Enter long trade\n",
    "        while (i + count) < len(test)-1 and test.iloc[i + count]['z_score_rsi'] <= exit_threshold and count <= 1875:\n",
    "            test.iloc[i + count]['long_signal_rsi'] = 1  # Stay in long trade\n",
    "            count += 1\n",
    "        test.iloc[i + count]['long_signal_rsi'] = 3  # Exit long trade\n",
    "    if count>1875:\n",
    "        i = i+count+1\n",
    "    else:\n",
    "        i=i+count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd9dad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['long_signal_rsi'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb337db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_Entry_long_rsi = test['long_signal_rsi'].value_counts()[2]\n",
    "count_Exit_long_rsi = test['long_signal_rsi'].value_counts()[3]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b59bec2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b522e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc037c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We calculate P/L for each entry and exit, and then for net P/L we take difference of both later depending on long/short.\n",
    "\n",
    "test.insert(loc=7,column='P/L_rsi',value=0)\n",
    "test.loc[test['short_signal_rsi']==2,'P/L_rsi']=test['residual_spread']*((test['tte'])**0.7)\n",
    "test.loc[test['short_signal_rsi']==2,'P/L_rsi']=test['residual_spread']*((test['tte'])**0.7)\n",
    "test.loc[test['long_signal_rsi']==3,'P/L_rsi']=test['residual_spread']*((test['tte'])**0.7)\n",
    "test.loc[test['long_signal_rsi']==3,'P/L_rsi']=test['residual_spread']*((test['tte'])**0.7)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3257540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let us calculate net_p/l first for both long and short positions:\n",
    "\n",
    "entry_1_rsi=test.loc[test['short_signal_rsi']==2,'P/L_rsi'].sum()\n",
    "exit_1_rsi=test.loc[test['short_signal_rsi']==3,'P/L_rsi'].sum()\n",
    "#this is shorting the spread hence entry - exit\n",
    "return_1_rsi=(entry_1_rsi-exit_1_rsi)\n",
    "print(return_1_rsi)\n",
    "\n",
    "entry_2_rsi=test.loc[test['long_signal_rsi']==2,'P/L_rsi'].sum()\n",
    "exit_2_rsi=test.loc[test['long_signal_rsi']==3,'P/L_rsi'].sum()\n",
    "#this is long on the spread hence exit - entry\n",
    "return_2_rsi=(exit_2_rsi-entry_2_rsi)\n",
    "print(return_2_rsi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92300226",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
